{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intent-Based Classification for RAG\n",
    "\n",
    "The difference between demo RAG and production RAG is often one thing:\n",
    "**Stop treating every query the same.**\n",
    "\n",
    "This notebook walks through:\n",
    "1. The problem with naive RAG\n",
    "2. How intent classification works\n",
    "3. Routing queries to different retrieval strategies\n",
    "4. A complete working example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem\n",
    "\n",
    "Naive RAG treats every query the same:\n",
    "\n",
    "```\n",
    "Query → Embed → Vector Search → Stuff into Prompt → Generate\n",
    "```\n",
    "\n",
    "But different queries need different approaches:\n",
    "\n",
    "| Query | What it needs | Naive RAG does |\n",
    "|-------|--------------|----------------|\n",
    "| \"What was Q3 revenue?\" | Database lookup | Searches 50k document chunks |\n",
    "| \"How do I reset my API key?\" | Exact steps, keywords matter | Returns vague conceptual text |\n",
    "| \"What is OAuth?\" | Broad explanation | Works okay, but suboptimal |\n",
    "| \"Postgres vs MongoDB?\" | Info on BOTH, then compare | Only retrieves one side |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Solution: Classify Before You Retrieve\n",
    "\n",
    "Add ONE step before your RAG pipeline:\n",
    "\n",
    "```\n",
    "Query → CLASSIFY INTENT → Route to Strategy → Retrieve → Generate\n",
    "```\n",
    "\n",
    "The classification step is cheap (one fast LLM call, ~50ms) and determines which retrieval strategy to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's look at the intent categories we'll use\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "class Intent(str, Enum):\n",
    "    \"\"\"The different types of queries a user might ask.\"\"\"\n",
    "    \n",
    "    CONCEPTUAL = \"conceptual\"      # \"What is X?\" - needs broad context\n",
    "    PROCEDURAL = \"procedural\"      # \"How do I X?\" - needs specific steps  \n",
    "    FACTUAL = \"factual\"            # \"What was X?\" - needs data lookup\n",
    "    COMPARATIVE = \"comparative\"    # \"X vs Y?\" - needs multi-source synthesis\n",
    "    OUT_OF_SCOPE = \"out_of_scope\"  # Off-topic - don't search at all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Classification Prompt\n",
    "\n",
    "Intent classification is just a specialized prompt. We ask a fast LLM to categorize the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFICATION_PROMPT = \"\"\"You are a query classifier for a software documentation system.\n",
    "\n",
    "Classify the user's query into exactly ONE category:\n",
    "\n",
    "CONCEPTUAL - Questions about what something is or how it works at a high level.\n",
    "Examples: \"What is a JWT?\", \"Explain OAuth\"\n",
    "\n",
    "PROCEDURAL - Questions about how to do something specific, step-by-step.\n",
    "Examples: \"How do I reset my API key?\", \"Show me how to deploy\"\n",
    "\n",
    "FACTUAL - Questions asking for specific data, numbers, or lookups.\n",
    "Examples: \"What was our Q3 revenue?\", \"What's the API rate limit?\"\n",
    "\n",
    "COMPARATIVE - Questions comparing two or more options.\n",
    "Examples: \"Should I use Postgres or MongoDB?\", \"REST vs GraphQL?\"\n",
    "\n",
    "OUT_OF_SCOPE - Questions unrelated to our software/documentation.\n",
    "Examples: \"What's the weather?\", \"Tell me a joke\"\n",
    "\n",
    "Respond with ONLY the category name in uppercase. Nothing else.\n",
    "\n",
    "Query: {query}\"\"\"\n",
    "\n",
    "print(\"Classification prompt template created.\")\n",
    "print(f\"\\nExample for 'How do I reset my password?':\\n\")\n",
    "print(CLASSIFICATION_PROMPT.format(query=\"How do I reset my password?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live Classification\n",
    "\n",
    "Let's classify some real queries using the OpenAI Responses API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def classify_query(query: str) -> str:\n",
    "    \"\"\"Classify a query into one of our intent categories.\"\"\"\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o-mini\",  # Fast model for classification\n",
    "        input=CLASSIFICATION_PROMPT.format(query=query),\n",
    "    )\n",
    "    return response.output_text.strip()\n",
    "\n",
    "# Test with different query types\n",
    "test_queries = [\n",
    "    \"What is a JWT?\",\n",
    "    \"How do I reset my API key?\",\n",
    "    \"What was our Q3 revenue?\",\n",
    "    \"Should I use Postgres or MongoDB?\",\n",
    "    \"What's the weather like today?\"\n",
    "]\n",
    "\n",
    "print(\"Query Classification Results:\\n\")\n",
    "for query in test_queries:\n",
    "    intent = classify_query(query)\n",
    "    print(f\"  '{query}'\")\n",
    "    print(f\"  → {intent}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Routing to Different Retrieval Strategies\n",
    "\n",
    "Once we know the intent, we route to the appropriate retrieval strategy.\n",
    "\n",
    "Each strategy is optimized for its query type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our mock retrieval strategies\n",
    "from retrieval import (\n",
    "    semantic_search,\n",
    "    hybrid_search, \n",
    "    structured_query,\n",
    "    multi_source_retrieval,\n",
    "    early_exit\n",
    ")\n",
    "\n",
    "def route_to_retrieval(intent: str, query: str):\n",
    "    \"\"\"Route to the appropriate retrieval strategy based on intent.\"\"\"\n",
    "    \n",
    "    match intent:\n",
    "        case \"CONCEPTUAL\":\n",
    "            # Broad understanding needed\n",
    "            # Use semantic/vector search with larger chunks\n",
    "            return semantic_search(query)\n",
    "            \n",
    "        case \"PROCEDURAL\":\n",
    "            # Specific steps needed, keywords matter\n",
    "            # Use hybrid search (vector + keyword)\n",
    "            return hybrid_search(query)\n",
    "            \n",
    "        case \"FACTUAL\":\n",
    "            # Data lookup needed\n",
    "            # Skip vectors entirely - query database directly\n",
    "            return structured_query(query)\n",
    "            \n",
    "        case \"COMPARATIVE\":\n",
    "            # Need info on multiple items\n",
    "            # Retrieve from multiple sources, then synthesize\n",
    "            return multi_source_retrieval(query)\n",
    "            \n",
    "        case \"OUT_OF_SCOPE\":\n",
    "            # Don't search at all\n",
    "            # Return canned response immediately\n",
    "            return early_exit(query)\n",
    "            \n",
    "        case _:\n",
    "            # Fallback to semantic search\n",
    "            return semantic_search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Example: Query → Classify → Route → Retrieve\n",
    "\n",
    "Let's put it all together and trace through a few queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query: str) -> dict:\n",
    "    \"\"\"Complete pipeline: classify → route → retrieve.\"\"\"\n",
    "    \n",
    "    # Step 1: Classify\n",
    "    intent = classify_query(query)\n",
    "    \n",
    "    # Step 2: Route to retrieval\n",
    "    result = route_to_retrieval(intent, query)\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"intent\": intent,\n",
    "        \"strategy\": result.strategy_used,\n",
    "        \"chunks\": result.chunks,\n",
    "        \"metadata\": result.metadata\n",
    "    }\n",
    "\n",
    "# Process a FACTUAL query\n",
    "result = process_query(\"What was our Q3 revenue?\")\n",
    "\n",
    "print(f\"Query: {result['query']}\")\n",
    "print(f\"Intent: {result['intent']}\")\n",
    "print(f\"Strategy: {result['strategy']}\")\n",
    "print(f\"Retrieved: {result['chunks']}\")\n",
    "print(f\"\\nNote: This skipped vector search entirely!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a PROCEDURAL query\n",
    "result = process_query(\"How do I reset my API key?\")\n",
    "\n",
    "print(f\"Query: {result['query']}\")\n",
    "print(f\"Intent: {result['intent']}\")\n",
    "print(f\"Strategy: {result['strategy']}\")\n",
    "print(f\"\\nRetrieved steps:\")\n",
    "print(result['chunks'][0][:500] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a COMPARATIVE query\n",
    "result = process_query(\"Should I use Postgres or MongoDB?\")\n",
    "\n",
    "print(f\"Query: {result['query']}\")\n",
    "print(f\"Intent: {result['intent']}\")\n",
    "print(f\"Strategy: {result['strategy']}\")\n",
    "print(f\"\\nRetrieved comparison data:\")\n",
    "for chunk in result['chunks']:\n",
    "    print(f\"  {chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process an OUT_OF_SCOPE query\n",
    "result = process_query(\"What's the weather like today?\")\n",
    "\n",
    "print(f\"Query: {result['query']}\")\n",
    "print(f\"Intent: {result['intent']}\")\n",
    "print(f\"Strategy: {result['strategy']}\")\n",
    "print(f\"\\nResponse: {result['chunks'][0]}\")\n",
    "print(f\"\\nMetadata: {result['metadata']}\")\n",
    "print(\"\\nNote: No search performed! Early exit saves tokens and latency.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why This Makes Your System FASTER\n",
    "\n",
    "Counter-intuitive: adding a classification step often reduces latency.\n",
    "\n",
    "**Without routing (naive RAG):**\n",
    "Every query runs the full pipeline:\n",
    "- Embed query (~50ms)\n",
    "- Vector search (~100ms)\n",
    "- Maybe rerank (~200ms)\n",
    "- Generate answer (~500ms)\n",
    "- **Total: ~850ms**\n",
    "\n",
    "**With routing:**\n",
    "- Classification (~50ms)\n",
    "- Then ONE of:\n",
    "  - Factual → SQL query (~20ms) → Skip expensive LLM\n",
    "  - Out of scope → Cached response (~0ms)\n",
    "  - Procedural → Targeted hybrid search (~80ms)\n",
    "  - etc.\n",
    "\n",
    "You're not adding latency. You're adding a cheap check that skips expensive operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "1. **The Problem**: Naive RAG uses the same retrieval for all query types\n",
    "\n",
    "2. **The Solution**: Classify intent BEFORE you retrieve\n",
    "\n",
    "3. **The Categories**:\n",
    "   - CONCEPTUAL → Semantic search with large chunks\n",
    "   - PROCEDURAL → Hybrid search (keywords matter)\n",
    "   - FACTUAL → Skip vectors, query database directly\n",
    "   - COMPARATIVE → Multi-source retrieval\n",
    "   - OUT_OF_SCOPE → Early exit, don't search\n",
    "\n",
    "4. **The Benefit**: Better accuracy AND often lower latency\n",
    "\n",
    "This is one of the key patterns that separates demo RAG from production RAG."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
